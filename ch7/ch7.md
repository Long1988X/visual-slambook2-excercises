[toc]

# 第7讲 视觉里程计1

## 1. 目标

1. 理解图像特征点的意义，并掌握在单幅图像中提取特征点及多幅图像中匹配特征点的方法。
2. 理解对极几何的原理，利用对极几何的约束，恢复图像之间的摄像机的三维运动。
3. 理解PNP问题，以及利用已知三维结构与图像的对应关系求解摄像机的三维运动。
4. 理解ICP问题，以及利用点云的匹配关系求解摄像机的三维运动。
5. 理解如何通过三角化获得二维图像上对应点的三维结构。

## 2. 知识点

1. ORB特征点提取与匹配：

   1. 关键点提取：FAST算法；
   2. 旋转角度计算：灰度质心角；
   3. 描述自计算；
   4. 特征匹配：暴力匹配、==快速最近邻(FLANN)==；
   5. ==动态物体ORB特征匹配问题；==

2. 2D-2D：对极几何

   1. 特征匹配后，得到特征点之间的关系；==如何处理匹配不正确的特征点对==
   2. 求本质矩阵$E$、单应矩阵$H$；
   3. 通过$E\ 、H$求出$R、t$; (==$E$的奇异值分解SVD==)
   4. 在已知$R、t$后，利用==三角化==计算特征点的3D位置（即深度）；（==纯旋转无法使用三角测量==）
   5. 实际中用于==单目SLAM的初始化部分==；

3. 3D-2D：PnP

   1. 描述：

      > 已知：两张图像$I_1、I_2$的特征点及特征匹配$Matches$，及**两张图像中的一张$I_1$特征点的3D位置**（相机坐标系下）；
      >
      > 求解：相机运动$R、t$；

   2. PnP问题求解方法：

      1. 线性方法：
      2. 非线性优化：
      3. 在SLAM中，通常的做法是先使用P3P/EPnP等方法估计相机位姿，在构建最小二乘优化问题，对估计值进行调整（即进行Bundle Adjustment）

   3. $I_1$特征点的3D位置如何确定？

      * 三角化测量
      * 双目相机深度图
      * RGB-D相机深度图

   4. 3D-3D：ICP

      1. 描述：

         > 已知：一组匹配好的3D点，相机1时刻3D点$\boldsymbol{P}=\left\{ \boldsymbol{p}_1\text{，}\boldsymbol{……}\text{，}\boldsymbol{p}_n \right\} $，相机2时刻3D点$\boldsymbol {P}^{'} =\left\{ \boldsymbol{p}_{1}^{'}\text{，}\boldsymbol{……}\text{，}\boldsymbol{p}_{n}^{'} \right\} $；
         >
         > 求解：一个欧式变换$R、t$，使得：$\boldsymbol{p}_{\boldsymbol{i}}=\boldsymbol{Rp}_{\boldsymbol{i}}^{'}+\boldsymbol{t} $
         >
         > 这里的$R、t$是第二帧到第一帧的变换；

      2. 求解方法

         * SVD：利用线性代数求解

           1. 计算两组点的质心位置$\boldsymbol{p}$，$ \boldsymbol{p}^{'}$，然后计算每个点的去质心坐标$\boldsymbol{q}_{\boldsymbol{i}}=\boldsymbol{p}_{\boldsymbol{i}}-\boldsymbol{p}$，$\boldsymbol{q}_{\boldsymbol{i}}^{'}=\boldsymbol{p}_{\boldsymbol{i}}^{'}-\boldsymbol{p}^{'}$

           2. 根据以下优化问题，计算旋转矩阵：$\boldsymbol{R}^*=\boldsymbol{arg}\underset{\boldsymbol{R}}{\min}\frac{1}{2}\sum_{\boldsymbol{i}=1}^{\boldsymbol{n}}{\lVert \boldsymbol{q}_{\boldsymbol{i}}-\boldsymbol{Rq}_{\boldsymbol{i}}^{'} \rVert ^2}$

           3. 根据第2步的$R$计算$t$：$\boldsymbol{t}^*=\boldsymbol{p}-\boldsymbol{Rp}^{'}$

         * BA：利用非线性优化方式

           1. 以李代数表达位姿时，目标函数？
           2. 单个误差项关于位姿的导数？
           3. 李代数扰动模型

## 3. 实践

1. ORB特征点提取与匹配
   1. ==问题==：耗费时间！
      1. 特征提取：opencv的orb提取算法(>100ms)比自己手写的orb特征提取(<5ms)更耗时间;
      2. 特征匹配：
         1. 暴力匹配算法在不使用任何cpu加速指令时，当特征点比较多时，非常耗时，大于100ms；
         2. 尝试FLANN、SIFT及其他加速匹配算法；
2. 位姿估计 - 2D-2D
   1. 获取$I_1、I_2$图像；
   2. 提取ORB特征并匹配；
   3. 计算本质矩阵，并获得$R、t$；
3. 三角化测距
4. 位姿估计 - 3D-2D
   1. ==关键：如何获取特征点的3D信息！==
   2. 方法：OpenCV、高斯牛顿法、g2o； 最高耗时1ms（OpenCV）
5. 位姿估计 - 3D-3D
6. OpenCV调用ORB、SIFT、SURF三种提取特征点，比较用时。
7. ==重点+难点：g2o库的理解与应用==；

## 4. 课后习题

1. 除了本书介绍的ORB特征点，你还能找到哪些特征点？

   请说说SIFT和SURF的原理，并对比它们与ORB之间的优劣。

   > 除了ORB之外，一般还有还有**SIFT、SURF、BRISK、AKAZE**，这些都是在OpenCV中已经实现了的。
   >
   > SIFT算法，又称为尺度不变特征转换(Scale-invariant feature transform），大致方法是首先搜索所有尺度下图像的位置，通过高斯微分函数来识别潜在的对于尺度和旋转不变的兴趣点，然后在候选位置通过拟合精细的模型来确定位置和尺度，再基于图像梯度，分配给关键点一个或多个方向，最后在每个关键点的周围邻域，在选定的尺度下测量图像局部梯度来描述关键点。使用斑点检测方法和浮点型特征描述子，在建立高斯差分空间金字塔的基础上提取初具有尺度不变性的特征点，然后对特征点邻域内的点的梯度方向进行直方图统计。特征点的主方向就是直方图中比重最大的方向，必要时可选一个辅方向。SIFT特征集旋转不变性，尺度不变性，对图像变形和光照鲁棒鲁等优点于一身，不足之处是计算量大，计算速度慢，需要GPU加速才可满足实时性需求。
   >
   > SURF算法，又称为加速稳健特征（Speeded Up Robust Features)，其方法和构建图像金字塔的方法相反，其主要方法是通过修改滤波器的尺寸和模糊度从而得到不同层级的影像，但是寻找特征点的方法和SIFT类似。使用基于DoH的斑点特征检测方法，在特征点的描述上，SURF算法通过积分图，利用两个方向上的Harr小波模型进行梯度计算，然后对邻域内点的梯度方向以扇形的方式进行统计，得到特征点的主方向。其算法速度快且稳定性好。
   >
   > SIFT和SURF能够比较稳定地提供较高的准确率，其中SIFT比SURF跟准确一点，但是二者都特别慢。相较而言ORB速度更快，但是更容易出现问题，而且错误率远比其他二者大。
   >
   > 计算速度： ORB>>SURF>>SIFT（各差一个量级）
   > 旋转鲁棒性： SURF>ORB~SIFT（表示差不多）
   > 模糊鲁棒性： SURF>ORB~SIFT
   > 尺度变换鲁棒性： SURF>SIFT>ORB（ORB并不具备尺度变换性）
   >
   > ==综上所述==，如果对计算实时性要求非常高，可选用ORB算法，但基本要保证正对拍摄；如果对实行性要求稍高，可以选择SURF；基本不用SIFT。

2. 设计程序调用OpenCV中的其他种类特征点。

   统计在提取1000个特征点时，在你的机器上所用的时间。

   > 在opencv3中，SURF/SIFT 以及其它的一些东西被移动到了独立的库(opencv_contrib)中。
   >
   > 如果你用的是opencv2可以省略安装opencv_contrib这一步骤

3. 我们发现，OpenCV提供的ORB特征点在图像中分布不够均匀。

   你是否能够找到或提出让特征点分布更均匀的方法？

   > 1. 利用==非极大值抑制==取出局部较密集特征点的思想：使用非极大值抑制算法去除临近位置多个特征点的问题。为每一个特征点计算出其响应大小。计算方式是一个特征点和其周围n个特征点偏差的绝对值和。在比较临近的特征点中，保留响应值较大的特征点，删除其余的特征点。
   > 2. 2016年出的ORB_SLAM2中已经==用四叉树实现的特征点均匀分布==算法。四叉树均匀划分的方法跟经典ORB算法变化不大，一般还是：1.构建图像金字塔；2.将每层图像划分网格，FAST算法提取特征点；3.对网格内的特征点进行评估，选取质量最好的留下作为代表关键点；4.用强度质心法计算每个关键点的方向；5对金字塔图层进行高斯滤波；6.使用BRIEF计算各个关键点的描述子（包含论文中的启发式搜索算法得到的256对匹配对坐标进行优化）；7.保留关键点和描述子。

4. 研究FLANN为何能够快速处理匹配问题。

   除了FLANN，还有哪些可以加速匹配的手段？

   > 加速匹配的方法：预排序图像检索；GPU加速，可以使得匹配速度提高十多倍；再后来就是用FPGA加速，其匹配速度能提升10倍；再后来的VF-SIFT（very fast SIFT）算法，其核心思想是从SIFT特征中提取4个特征角，根据特征角区间的不同，避免了大量不必要的搜索，这样据说是普通搜索的1250倍。

5. 把演示程序使用的EPnP改成其他PnP方法，并研究它们的工作原理。

6. 在PnP优化中，将第一个相机的观测也考虑进来，程序应如何书写？

   最后结果会有何变化？

7. 在ICP程序中，将空间点也作为优化变量考虑进来，程序应如何书写？

   最后结果会有何变化？

8. 在特征点匹配过程中，不可避免地会遇到误匹配的情况。

   如果我们把错误匹配输入到PnP或ICP中，会发生怎样的情况？你能想到哪些避免误匹配的方法？

   > 1. 目前书中用的是根据汉明距离的暴力匹配方法，然后根据经验参数（30或者是最小距离的两倍）对匹配子根据其距离进行筛选。如果误匹配情况输入到PnP或是ICP中，再加上迭代算法选择不正确，初值估计不准确，就很容易导致计算结果产生误差，更有甚者会让迭代过程不稳定，甚至报错。
   > 2. 目前比较流行的避免误匹配方法有：交叉匹配（在暴力匹配的基础上再匹配一次，如果两次结果一致，则认为是个特征点，如果不一致则滤掉，BFMatcher XX (NORM_HAMMING, true) ）、KNN匹配（K邻近匹配，匹配时候选择K个与特征点相似的点，一般K是2，如果区别足够大，则选择最相似的点作为匹配点，bfMatcher->knnMatch(descriptors1, descriptors2, knnMatches, 2) ）、RANSAC（随机采样一致性，利用两个图像之间的单应矩阵，根据重投影误差判定某个匹配是不是正确匹配，findHomography）等等，一般可以跟觉已有的成熟框架如ORB_SLAM2等等观察其对于不同场景所采取的避免误匹配的方法。

9. 使用Sophus的SE3类，自己设计g2o的节点与边，实现PnP和ICP的优化。

10. 在Ceres中实现PnP和ICP的优化。
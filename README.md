# Visual SLAMBOOK 2 Exercises

1. Records of learning the book(slambook 2).
2. Include knowledge point of every chapter, practice codes, related papers etc.

# CONCLUSION

## Chapter 1

1. 一定注重编码实践！
2. 数学基础：
   * 书籍：《线性代数的几何意义》《Introduction to Linear Algebra》
   * 视频：3Blue1Brown - <微积分的本质> <线性代数的本质>     《MIT 18.06 Linear Algebra》
3. C++基础：
   * 书籍：《C++ Primer》
   * 视频：侯捷 《C++面向对象高级开发》
4. Linux基础：
   * 书籍：《鸟哥的Linux私房菜.基础学习篇》《Linux就该这么学》
   * 了解Linux文件架构、知道如何安装、卸载软件；
5. 编译基础：
   * 书籍：《CMake Practice》
   * 知道基本的Linux下的软件开发架构，及编译原理；
6. 其他基础：
   * 泰勒展开
   * 贝叶斯法则

## Chapter 2 初识SLAM

1. 视觉SLAM框架

   ![image-20211220165802225](/home/pikachu/.config/Typora/typora-user-images/image-20211220165802225.png)

2. SLAM问题的数学表述

   ![image-20211220165945643](/home/pikachu/.config/Typora/typora-user-images/image-20211220165945643.png)

3. 编程基础

   * Linux下C++编程
   * CMake编译程序
     * 使用第三方库
     * 编译动态库和静态库
     * 编译成可执行文件
     * FINDXXX.cmake
     * CMAKE变量和系统变量

## 第3讲 三维空间刚体运动

1. 理解三维空间的刚体运动描述方式：旋转矩阵、旋转向量、欧拉角、四元数及变换矩阵；
2. 掌握Eigen库的矩阵、几何模型的使用方法；$Isometry3d\ T$
3. 理解$SO(3)\ SE(3)$；
4. 掌握罗德里格斯公式的证明；
5. 四元数的运算；
6. 四元数到其他旋转表示的转换；
7. Pangolin库的GUI功能；相机位姿和轨迹绘制；

## 第4讲 李群与李代数

1. 理解群、李群、李代数的概念与定义；
2. 理解群与李代数满足的性质；
3. 理解$SO(3)和SE(3)$的定义；
4. 理解$so(3)和se(3)$的定义；
5. 推导$SO(3)与so(3)$指数与对数映射；
6. 推导$SE(3)与se(3)$指数与对数映射；
7. 掌握$BCH$近似公式的表达及其意义；
8. 推导$SO(3)$上的李代数求导与左扰动模型；
9. 推导$SE(3)$上的李代数求导与左扰动模型；
10. 试着推导右扰动模型；
11. Sophus库；

## 第5讲 相机与图像

1. 相机模型

   * 针孔相机模型
   * 畸变模型：径向和切向畸变

2. 单目相机成像过程

   > 世界坐标系    ->    相机坐标系     ->     归一化平面(根据畸变参数计算畸变后的坐标)     ->    像素坐标系

3. 双目相机成像模型

4. RGB-D相机原理：红外结构光和飞行时间。

5. 扩展：

   * 相机标定原理、分类及程序；
   * 单目深度估计；
   * 双目视差图算法；

## 第6讲 非线性优化

1. 如何在有噪声的数据中进行准确的状态估计；
2. 最优化背景知识；
3. 批量状态估计：
   1. 贝叶斯法则：最大后验估计和最大似然估计；
   2. 最大似然 ->  最小二乘；
4. 非线性最小二乘：
   1. **迭代的方法**：对于不容易直接求解的最小二乘问题；
   2. 一阶梯度法(最速下降法)：Jacobian Matrix；
   3. 二阶梯度法(牛顿法)：Hessian Matrix；
   4. 高斯牛顿法：**回避H矩阵的求解，用J的表达式近似了H**；
   5. 列文伯格-马夸尔特法：置信区间；
5. 与线性规划不同，非线性需要针对具体问题具体分析；

## 第7讲 视觉里程计1

1. ORB特征点提取与匹配：

   1. 关键点提取：FAST算法；
   2. 旋转角度计算：灰度质心角；
   3. 描述自计算；
   4. 特征匹配：暴力匹配、==快速最近邻(FLANN)==；
   5. ==动态物体ORB特征匹配问题；==

2. 2D-2D：对极几何

   1. 特征匹配后，得到特征点之间的关系；==如何处理匹配不正确的特征点对==
   2. 求本质矩阵$E$、单应矩阵$H$；
   3. 通过$E\ 、H$求出$R、t$; (==$E$的奇异值分解SVD==)
   4. 在已知$R、t$后，利用==三角化==计算特征点的3D位置（即深度）；（==纯旋转无法使用三角测量==）
   5. 实际中用于==单目SLAM的初始化部分==；

3. 3D-2D：PnP

   1. 描述：

      > 已知：两张图像$I_1、I_2$的特征点及特征匹配$Matches$，及**两张图像中的一张$I_1$特征点的3D位置**（相机坐标系下）；
      >
      > 求解：相机运动$R、t$；

   2. PnP问题求解方法：

      1. 线性方法：
      2. 非线性优化：
      3. 在SLAM中，通常的做法是先使用P3P/EPnP等方法估计相机位姿，在构建最小二乘优化问题，对估计值进行调整（即进行Bundle Adjustment）

   3. $I_1$特征点的3D位置如何确定？

      * 三角化测量
      * 双目相机深度图
      * RGB-D相机深度图

   4. 3D-3D：ICP

      1. 描述：

         > 已知：一组匹配好的3D点，相机1时刻3D点$\boldsymbol{P}=\left\{ \boldsymbol{p}_1\text{，}\boldsymbol{……}\text{，}\boldsymbol{p}_n \right\} $，相机2时刻3D点$\boldsymbol {P}^{'} =\left\{ \boldsymbol{p}_{1}^{'}\text{，}\boldsymbol{……}\text{，}\boldsymbol{p}_{n}^{'} \right\} $；
         >
         > 求解：一个欧式变换$R、t$，使得：$\boldsymbol{p}_{\boldsymbol{i}}=\boldsymbol{Rp}_{\boldsymbol{i}}^{'}+\boldsymbol{t} $
         >
         > 这里的$R、t$是第二帧到第一帧的变换；

      2. 求解方法

         * SVD：利用线性代数求解

           1. 计算两组点的质心位置$\boldsymbol{p}$，$ \boldsymbol{p}^{'}$，然后计算每个点的去质心坐标$\boldsymbol{q}_{\boldsymbol{i}}=\boldsymbol{p}_{\boldsymbol{i}}-\boldsymbol{p}$，$\boldsymbol{q}_{\boldsymbol{i}}^{'}=\boldsymbol{p}_{\boldsymbol{i}}^{'}-\boldsymbol{p}^{'}$

           2. 根据以下优化问题，计算旋转矩阵：$\boldsymbol{R}^*=\boldsymbol{arg}\underset{\boldsymbol{R}}{\min}\frac{1}{2}\sum_{\boldsymbol{i}=1}^{\boldsymbol{n}}{\lVert \boldsymbol{q}_{\boldsymbol{i}}-\boldsymbol{Rq}_{\boldsymbol{i}}^{'} \rVert ^2}$

           3. 根据第2步的$R$计算$t$：$\boldsymbol{t}^*=\boldsymbol{p}-\boldsymbol{Rp}^{'}$

         * BA：利用非线性优化方式

           1. 以李代数表达位姿时，目标函数？
           2. 单个误差项关于位姿的导数？
           3. 李代数扰动模型

   ## 第8讲 视觉里程计2

   1. 直接法的引出：
      1. 特征点法的缺点；
      2. 克服以上缺点的思路：
         * 光流法跟踪特征点运动；
         * 直接法计算特征点在下一刻图像的位置，同时估计相机运动和点的投影；
   2. 特征点法与直接法优化：
      1. 特征点法：最小化**重投影误差(Reprojection error)**；
      2. 直接法：最小化**光度误差(Photometric error)**。
   3. 2D光流：通过最小化灰度误差估计最优的像素偏移。
   4. 直接法：根据当前相机的位姿估计寻找哦$p_2$的位置。==优化变量是相机位姿$T$==。

   ## 第9讲 后端1

   1. 卡尔曼滤波原理；
   2. Bundle Adjustment及图优化
      * 投影模型：世界坐标系(外参R、t) -> 相机坐标系(1/Z) -> 归一化平面(畸变公式) -> 畸变模型(内参模型) -> 像素坐标系
      * BA代价函数：观测数据是像素坐标[u, v]
      * 求解该最小二乘问题，相当于对位姿和路标(空间点)同时做了调整，也就是所谓的BA；
      * H矩阵稀疏性理解及稀疏性加速计算方法；==Schur消元==
   3. meshlab

   ## 第10讲 后端2

   1. 关键帧

   2. 滑动窗口法：取时间上靠近，空间上又可以展开的关键帧；

   3. 位姿图：

      > 1. 特征点在优化问题中占据了绝大部分；
      > 2. 实际上，经过若干次观测之后，收敛的特征点位置变化很小，发散的外点则已被剔除；
      > 3. 对收敛点再进行优化，似乎是有些费力不讨好。
      > 4. 更倾向于，在优化几次之后就把特征点固定住。
      > 5. 继续思考：是否能够完全不管路标而只管轨迹呢？
      > 6. 如果有额外测量Pose的传感器，那么位姿图也是一种常见的融合Pose测量的方法。

   ## 第11讲 回环检测

   1. 回环检测的意义：

      > 1. 关系到估计的轨迹和地图在长时间下的正确性；
      > 2. 可以利用回环检测进行重定位；

   2. 回环检测的方法：

      > 1. 最简单的方式：对任意两幅图像都做一遍特征匹配；
      > 2. 另一种朴素方法：随机抽取历史数据并进行回环检测；
      > 3. 基于外观的，仅根据**两幅图像的相似性**确定回环检测关系；
      > 4. **词袋，Bag-of-Words**，目的是用“图像上有哪几种特征”来描述一幅图像；
      > 5. **字典**，由很多单词组成，聚类问题；
      > 6. 相似度计算；

   3. 回环检测的步骤：

      > 检测到回环的发生
      >
      > 计算回环修选帧与当前帧的运动
      >
      > 验证回环是否成立
      >
      > 闭环

   4. 回环检测的指标：

      > 1. 准确率：所有回环中确实是真实回环的概率；
      > 2. 召回率：所有真实回环中被正确检测出来的概率；

   ## 第12讲 建图

   1. 希望地图能够用于定位、导航、避障和交互。
   2. 经典SLAM中所谓的地图，即所有路标点的集合。
   3. 稀疏地图，可能只建模了桌子的四个角；
   4. 稠密地图，则会建模整个桌面。
   5. 稠密重建：需要知道每一个像素点(或大部分像素点)的距离。
      1. 单目相机：估计相机运动，并三角化计算像素的距离；
      2. 双目相机：利用左右目的视差计算像素的距离；
      3. RGB-D相机：直接获得像素距离。
   6. 扩展
      1. 占据栅格地图
      2. 2.5D地图
      3. 八叉树地图

   ## 第13讲 实践：设计SLAM系统

   1. 精简版的双目视觉里程计：

      > 1. 使用Kitti数据集；
      > 2. 由一个光流追踪的前端和一个局部BA的后端组成。

